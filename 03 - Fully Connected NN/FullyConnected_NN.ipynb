{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set is: 60000\n",
      "size of testing set is: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# define hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 1e-2\n",
    "num_epochs = 50\n",
    "\n",
    "# download MNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./datasets', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./datasets', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f'size of training set is: {len(train_loader.dataset)}')\n",
    "print(f'size of testing set is: {len(test_loader.dataset)}')\n",
    "\n",
    "# define model: a 3-layer fully connected neural network\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, in_dim, n_layer1, n_layer2, out_dim):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_layer1)\n",
    "        self.layer2 = nn.Linear(n_layer1, n_layer2)\n",
    "        self.layer3 = nn.Linear(n_layer2, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "        \n",
    "model = FullyConnectedNN(28 * 28, 300, 100, 10)  # image size is 28x28\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] Loss: 1.686254, Acc: 0.540104\n",
      "[1/50] Loss: 1.329801, Acc: 0.605365\n",
      "[1/50] Loss: 1.148804, Acc: 0.644132\n",
      "[1/50] Loss: 1.038376, Acc: 0.670807\n",
      "[1/50] Loss: 0.957945, Acc: 0.693000\n",
      "[1/50] Loss: 0.900012, Acc: 0.709323\n",
      "Finish 1 epochs, Loss: 0.887772, Acc: 0.713000\n",
      "Test Loss: 0.603589, Acc: 0.785244\n",
      "[2/50] Loss: 0.569670, Acc: 0.804688\n",
      "[2/50] Loss: 0.557351, Acc: 0.808542\n",
      "[2/50] Loss: 0.541870, Acc: 0.814826\n",
      "[2/50] Loss: 0.539221, Acc: 0.814453\n",
      "[2/50] Loss: 0.538766, Acc: 0.814417\n",
      "[2/50] Loss: 0.534279, Acc: 0.815486\n",
      "Finish 2 epochs, Loss: 0.531916, Acc: 0.816300\n",
      "Test Loss: 0.549383, Acc: 0.795927\n",
      "[3/50] Loss: 0.491340, Acc: 0.832813\n",
      "[3/50] Loss: 0.481378, Acc: 0.835885\n",
      "[3/50] Loss: 0.484162, Acc: 0.833542\n",
      "[3/50] Loss: 0.485529, Acc: 0.832656\n",
      "[3/50] Loss: 0.482012, Acc: 0.832792\n",
      "[3/50] Loss: 0.483350, Acc: 0.831597\n",
      "Finish 3 epochs, Loss: 0.482812, Acc: 0.831767\n",
      "Test Loss: 0.498946, Acc: 0.823482\n",
      "[4/50] Loss: 0.447139, Acc: 0.844896\n",
      "[4/50] Loss: 0.450350, Acc: 0.840104\n",
      "[4/50] Loss: 0.454096, Acc: 0.839826\n",
      "[4/50] Loss: 0.459175, Acc: 0.838411\n",
      "[4/50] Loss: 0.460656, Acc: 0.838354\n",
      "[4/50] Loss: 0.459298, Acc: 0.838733\n",
      "Finish 4 epochs, Loss: 0.459181, Acc: 0.838933\n",
      "Test Loss: 0.481373, Acc: 0.828774\n",
      "[5/50] Loss: 0.444204, Acc: 0.845104\n",
      "[5/50] Loss: 0.448765, Acc: 0.843333\n",
      "[5/50] Loss: 0.446418, Acc: 0.842708\n",
      "[5/50] Loss: 0.447861, Acc: 0.843464\n",
      "[5/50] Loss: 0.445099, Acc: 0.844625\n",
      "[5/50] Loss: 0.445351, Acc: 0.845347\n",
      "Finish 5 epochs, Loss: 0.444987, Acc: 0.845917\n",
      "Test Loss: 0.478198, Acc: 0.826378\n",
      "[6/50] Loss: 0.446866, Acc: 0.843333\n",
      "[6/50] Loss: 0.437661, Acc: 0.846823\n",
      "[6/50] Loss: 0.436185, Acc: 0.847986\n",
      "[6/50] Loss: 0.435128, Acc: 0.847552\n",
      "[6/50] Loss: 0.435439, Acc: 0.847646\n",
      "[6/50] Loss: 0.435245, Acc: 0.847969\n",
      "Finish 6 epochs, Loss: 0.435418, Acc: 0.847933\n",
      "Test Loss: 0.470438, Acc: 0.833167\n",
      "[7/50] Loss: 0.410457, Acc: 0.855521\n",
      "[7/50] Loss: 0.423345, Acc: 0.853021\n",
      "[7/50] Loss: 0.425377, Acc: 0.851840\n",
      "[7/50] Loss: 0.425114, Acc: 0.851250\n",
      "[7/50] Loss: 0.426094, Acc: 0.850396\n",
      "[7/50] Loss: 0.426106, Acc: 0.850972\n",
      "Finish 7 epochs, Loss: 0.427889, Acc: 0.850550\n",
      "Test Loss: 0.483689, Acc: 0.828674\n",
      "[8/50] Loss: 0.412153, Acc: 0.856250\n",
      "[8/50] Loss: 0.422183, Acc: 0.853229\n",
      "[8/50] Loss: 0.421737, Acc: 0.851806\n",
      "[8/50] Loss: 0.421601, Acc: 0.852656\n",
      "[8/50] Loss: 0.420354, Acc: 0.852417\n",
      "[8/50] Loss: 0.421944, Acc: 0.852743\n",
      "Finish 8 epochs, Loss: 0.422354, Acc: 0.852500\n",
      "Test Loss: 0.460902, Acc: 0.833566\n",
      "[9/50] Loss: 0.408512, Acc: 0.859375\n",
      "[9/50] Loss: 0.413984, Acc: 0.855990\n",
      "[9/50] Loss: 0.413717, Acc: 0.856389\n",
      "[9/50] Loss: 0.413875, Acc: 0.856094\n",
      "[9/50] Loss: 0.416603, Acc: 0.855104\n",
      "[9/50] Loss: 0.418066, Acc: 0.853889\n",
      "Finish 9 epochs, Loss: 0.417530, Acc: 0.854133\n",
      "Test Loss: 0.457250, Acc: 0.837959\n",
      "[10/50] Loss: 0.414901, Acc: 0.852917\n",
      "[10/50] Loss: 0.413487, Acc: 0.855521\n",
      "[10/50] Loss: 0.416399, Acc: 0.855660\n",
      "[10/50] Loss: 0.413717, Acc: 0.855964\n",
      "[10/50] Loss: 0.414199, Acc: 0.856000\n",
      "[10/50] Loss: 0.414565, Acc: 0.855816\n",
      "Finish 10 epochs, Loss: 0.413972, Acc: 0.856050\n",
      "Test Loss: 0.449112, Acc: 0.841853\n",
      "[11/50] Loss: 0.401315, Acc: 0.859688\n",
      "[11/50] Loss: 0.407947, Acc: 0.856927\n",
      "[11/50] Loss: 0.411714, Acc: 0.854826\n",
      "[11/50] Loss: 0.417014, Acc: 0.854479\n",
      "[11/50] Loss: 0.412057, Acc: 0.856687\n",
      "[11/50] Loss: 0.410391, Acc: 0.856528\n",
      "Finish 11 epochs, Loss: 0.410550, Acc: 0.856333\n",
      "Test Loss: 0.457247, Acc: 0.838658\n",
      "[12/50] Loss: 0.418920, Acc: 0.855208\n",
      "[12/50] Loss: 0.408457, Acc: 0.857865\n",
      "[12/50] Loss: 0.406509, Acc: 0.858993\n",
      "[12/50] Loss: 0.407565, Acc: 0.858255\n",
      "[12/50] Loss: 0.410668, Acc: 0.857458\n",
      "[12/50] Loss: 0.407716, Acc: 0.858038\n",
      "Finish 12 epochs, Loss: 0.408462, Acc: 0.858000\n",
      "Test Loss: 0.450428, Acc: 0.840954\n",
      "[13/50] Loss: 0.401456, Acc: 0.858438\n",
      "[13/50] Loss: 0.406647, Acc: 0.859115\n",
      "[13/50] Loss: 0.406674, Acc: 0.857465\n",
      "[13/50] Loss: 0.408037, Acc: 0.855990\n",
      "[13/50] Loss: 0.406068, Acc: 0.857562\n",
      "[13/50] Loss: 0.405885, Acc: 0.857708\n",
      "Finish 13 epochs, Loss: 0.405907, Acc: 0.857833\n",
      "Test Loss: 0.452018, Acc: 0.839557\n",
      "[14/50] Loss: 0.410689, Acc: 0.857188\n",
      "[14/50] Loss: 0.404196, Acc: 0.858385\n",
      "[14/50] Loss: 0.402084, Acc: 0.858993\n",
      "[14/50] Loss: 0.403712, Acc: 0.859609\n",
      "[14/50] Loss: 0.403911, Acc: 0.859542\n",
      "[14/50] Loss: 0.404652, Acc: 0.859392\n",
      "Finish 14 epochs, Loss: 0.403920, Acc: 0.859433\n",
      "Test Loss: 0.442590, Acc: 0.842452\n",
      "[15/50] Loss: 0.404309, Acc: 0.857500\n",
      "[15/50] Loss: 0.396898, Acc: 0.861302\n",
      "[15/50] Loss: 0.401692, Acc: 0.859479\n",
      "[15/50] Loss: 0.400399, Acc: 0.860703\n",
      "[15/50] Loss: 0.404294, Acc: 0.858833\n",
      "[15/50] Loss: 0.401116, Acc: 0.859618\n",
      "Finish 15 epochs, Loss: 0.401358, Acc: 0.859767\n",
      "Test Loss: 0.443990, Acc: 0.843750\n",
      "[16/50] Loss: 0.385060, Acc: 0.862083\n",
      "[16/50] Loss: 0.396865, Acc: 0.859844\n",
      "[16/50] Loss: 0.400097, Acc: 0.859549\n",
      "[16/50] Loss: 0.397409, Acc: 0.861146\n",
      "[16/50] Loss: 0.396785, Acc: 0.861812\n",
      "[16/50] Loss: 0.398329, Acc: 0.861441\n",
      "Finish 16 epochs, Loss: 0.398819, Acc: 0.861400\n",
      "Test Loss: 0.457614, Acc: 0.837161\n",
      "[17/50] Loss: 0.404120, Acc: 0.857604\n",
      "[17/50] Loss: 0.404477, Acc: 0.857448\n",
      "[17/50] Loss: 0.396769, Acc: 0.861007\n",
      "[17/50] Loss: 0.398880, Acc: 0.860703\n",
      "[17/50] Loss: 0.397792, Acc: 0.860563\n",
      "[17/50] Loss: 0.399057, Acc: 0.860295\n",
      "Finish 17 epochs, Loss: 0.398414, Acc: 0.860517\n",
      "Test Loss: 0.443882, Acc: 0.843950\n",
      "[18/50] Loss: 0.383258, Acc: 0.864583\n",
      "[18/50] Loss: 0.393855, Acc: 0.862292\n",
      "[18/50] Loss: 0.394169, Acc: 0.862813\n",
      "[18/50] Loss: 0.391968, Acc: 0.862344\n",
      "[18/50] Loss: 0.394387, Acc: 0.861583\n",
      "[18/50] Loss: 0.395195, Acc: 0.861424\n",
      "Finish 18 epochs, Loss: 0.396175, Acc: 0.861233\n",
      "Test Loss: 0.451398, Acc: 0.840655\n",
      "[19/50] Loss: 0.405755, Acc: 0.856875\n",
      "[19/50] Loss: 0.391345, Acc: 0.861458\n",
      "[19/50] Loss: 0.392734, Acc: 0.861285\n",
      "[19/50] Loss: 0.397270, Acc: 0.860078\n",
      "[19/50] Loss: 0.394379, Acc: 0.861208\n",
      "[19/50] Loss: 0.393788, Acc: 0.861458\n",
      "Finish 19 epochs, Loss: 0.394514, Acc: 0.861283\n",
      "Test Loss: 0.458184, Acc: 0.837260\n",
      "[20/50] Loss: 0.399994, Acc: 0.859479\n",
      "[20/50] Loss: 0.398061, Acc: 0.859375\n",
      "[20/50] Loss: 0.397971, Acc: 0.860625\n",
      "[20/50] Loss: 0.394029, Acc: 0.861641\n",
      "[20/50] Loss: 0.392368, Acc: 0.862000\n",
      "[20/50] Loss: 0.394356, Acc: 0.861771\n",
      "Finish 20 epochs, Loss: 0.394135, Acc: 0.861850\n",
      "Test Loss: 0.444194, Acc: 0.840555\n",
      "[21/50] Loss: 0.389850, Acc: 0.867813\n",
      "[21/50] Loss: 0.392341, Acc: 0.865729\n",
      "[21/50] Loss: 0.395317, Acc: 0.865486\n",
      "[21/50] Loss: 0.393639, Acc: 0.864766\n",
      "[21/50] Loss: 0.394660, Acc: 0.863458\n",
      "[21/50] Loss: 0.393147, Acc: 0.863698\n",
      "Finish 21 epochs, Loss: 0.392330, Acc: 0.863833\n",
      "Test Loss: 0.438779, Acc: 0.843450\n",
      "[22/50] Loss: 0.381899, Acc: 0.861979\n",
      "[22/50] Loss: 0.386484, Acc: 0.859844\n",
      "[22/50] Loss: 0.390913, Acc: 0.860729\n",
      "[22/50] Loss: 0.391205, Acc: 0.861797\n",
      "[22/50] Loss: 0.390795, Acc: 0.861833\n",
      "[22/50] Loss: 0.390628, Acc: 0.862569\n",
      "Finish 22 epochs, Loss: 0.390260, Acc: 0.862833\n",
      "Test Loss: 0.449146, Acc: 0.841254\n",
      "[23/50] Loss: 0.388757, Acc: 0.861563\n",
      "[23/50] Loss: 0.385731, Acc: 0.864115\n",
      "[23/50] Loss: 0.389845, Acc: 0.862361\n",
      "[23/50] Loss: 0.388754, Acc: 0.862839\n",
      "[23/50] Loss: 0.389712, Acc: 0.863063\n",
      "[23/50] Loss: 0.390305, Acc: 0.862986\n",
      "Finish 23 epochs, Loss: 0.389447, Acc: 0.863467\n",
      "Test Loss: 0.438494, Acc: 0.846046\n",
      "[24/50] Loss: 0.386014, Acc: 0.864167\n",
      "[24/50] Loss: 0.386269, Acc: 0.865833\n",
      "[24/50] Loss: 0.389291, Acc: 0.863438\n",
      "[24/50] Loss: 0.391986, Acc: 0.862396\n",
      "[24/50] Loss: 0.389030, Acc: 0.862646\n",
      "[24/50] Loss: 0.389173, Acc: 0.863125\n",
      "Finish 24 epochs, Loss: 0.388996, Acc: 0.863400\n",
      "Test Loss: 0.447147, Acc: 0.841054\n",
      "[25/50] Loss: 0.381506, Acc: 0.865104\n",
      "[25/50] Loss: 0.384120, Acc: 0.866823\n",
      "[25/50] Loss: 0.382539, Acc: 0.867222\n",
      "[25/50] Loss: 0.383520, Acc: 0.866667\n",
      "[25/50] Loss: 0.385432, Acc: 0.865958\n",
      "[25/50] Loss: 0.385681, Acc: 0.865868\n",
      "Finish 25 epochs, Loss: 0.387482, Acc: 0.865217\n",
      "Test Loss: 0.437114, Acc: 0.847045\n",
      "[26/50] Loss: 0.388084, Acc: 0.861771\n",
      "[26/50] Loss: 0.383808, Acc: 0.863802\n",
      "[26/50] Loss: 0.387912, Acc: 0.862326\n",
      "[26/50] Loss: 0.386994, Acc: 0.863568\n",
      "[26/50] Loss: 0.385752, Acc: 0.863917\n",
      "[26/50] Loss: 0.387684, Acc: 0.863299\n",
      "Finish 26 epochs, Loss: 0.386512, Acc: 0.863733\n",
      "Test Loss: 0.447182, Acc: 0.842552\n",
      "[27/50] Loss: 0.377994, Acc: 0.868646\n",
      "[27/50] Loss: 0.379275, Acc: 0.867865\n",
      "[27/50] Loss: 0.381472, Acc: 0.867118\n",
      "[27/50] Loss: 0.382462, Acc: 0.866823\n",
      "[27/50] Loss: 0.383535, Acc: 0.866375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/50] Loss: 0.384263, Acc: 0.865868\n",
      "Finish 27 epochs, Loss: 0.385146, Acc: 0.865517\n",
      "Test Loss: 0.454036, Acc: 0.840755\n",
      "[28/50] Loss: 0.385761, Acc: 0.863333\n",
      "[28/50] Loss: 0.385005, Acc: 0.863490\n",
      "[28/50] Loss: 0.382630, Acc: 0.864306\n",
      "[28/50] Loss: 0.381408, Acc: 0.864844\n",
      "[28/50] Loss: 0.384652, Acc: 0.864729\n",
      "[28/50] Loss: 0.384399, Acc: 0.864792\n",
      "Finish 28 epochs, Loss: 0.384515, Acc: 0.864733\n",
      "Test Loss: 0.443637, Acc: 0.843051\n",
      "[29/50] Loss: 0.373580, Acc: 0.864688\n",
      "[29/50] Loss: 0.375713, Acc: 0.865417\n",
      "[29/50] Loss: 0.377111, Acc: 0.864792\n",
      "[29/50] Loss: 0.375763, Acc: 0.865234\n",
      "[29/50] Loss: 0.378349, Acc: 0.864917\n",
      "[29/50] Loss: 0.382894, Acc: 0.863906\n",
      "Finish 29 epochs, Loss: 0.383702, Acc: 0.863600\n",
      "Test Loss: 0.439544, Acc: 0.843650\n",
      "[30/50] Loss: 0.379596, Acc: 0.865417\n",
      "[30/50] Loss: 0.387234, Acc: 0.864010\n",
      "[30/50] Loss: 0.383817, Acc: 0.865938\n",
      "[30/50] Loss: 0.382686, Acc: 0.865755\n",
      "[30/50] Loss: 0.383536, Acc: 0.865292\n",
      "[30/50] Loss: 0.383385, Acc: 0.865625\n",
      "Finish 30 epochs, Loss: 0.383087, Acc: 0.865733\n",
      "Test Loss: 0.441104, Acc: 0.845647\n",
      "[31/50] Loss: 0.380144, Acc: 0.863229\n",
      "[31/50] Loss: 0.372454, Acc: 0.866458\n",
      "[31/50] Loss: 0.375190, Acc: 0.865382\n",
      "[31/50] Loss: 0.380007, Acc: 0.864115\n",
      "[31/50] Loss: 0.381834, Acc: 0.864708\n",
      "[31/50] Loss: 0.382561, Acc: 0.864931\n",
      "Finish 31 epochs, Loss: 0.382351, Acc: 0.864883\n",
      "Test Loss: 0.441430, Acc: 0.844050\n",
      "[32/50] Loss: 0.380631, Acc: 0.866458\n",
      "[32/50] Loss: 0.382081, Acc: 0.865104\n",
      "[32/50] Loss: 0.379666, Acc: 0.865799\n",
      "[32/50] Loss: 0.380009, Acc: 0.866302\n",
      "[32/50] Loss: 0.381933, Acc: 0.865292\n",
      "[32/50] Loss: 0.381704, Acc: 0.865816\n",
      "Finish 32 epochs, Loss: 0.381713, Acc: 0.865567\n",
      "Test Loss: 0.445872, Acc: 0.842951\n",
      "[33/50] Loss: 0.379891, Acc: 0.865625\n",
      "[33/50] Loss: 0.381974, Acc: 0.865521\n",
      "[33/50] Loss: 0.378854, Acc: 0.865694\n",
      "[33/50] Loss: 0.380317, Acc: 0.864922\n",
      "[33/50] Loss: 0.380670, Acc: 0.864729\n",
      "[33/50] Loss: 0.381003, Acc: 0.864896\n",
      "Finish 33 epochs, Loss: 0.381244, Acc: 0.864667\n",
      "Test Loss: 0.442887, Acc: 0.841853\n",
      "[34/50] Loss: 0.364092, Acc: 0.872604\n",
      "[34/50] Loss: 0.372697, Acc: 0.868802\n",
      "[34/50] Loss: 0.381104, Acc: 0.865590\n",
      "[34/50] Loss: 0.382996, Acc: 0.864661\n",
      "[34/50] Loss: 0.381438, Acc: 0.865271\n",
      "[34/50] Loss: 0.379907, Acc: 0.865486\n",
      "Finish 34 epochs, Loss: 0.381163, Acc: 0.865317\n",
      "Test Loss: 0.440527, Acc: 0.844549\n",
      "[35/50] Loss: 0.391277, Acc: 0.864792\n",
      "[35/50] Loss: 0.382244, Acc: 0.867552\n",
      "[35/50] Loss: 0.380668, Acc: 0.867153\n",
      "[35/50] Loss: 0.378731, Acc: 0.867109\n",
      "[35/50] Loss: 0.381978, Acc: 0.865375\n",
      "[35/50] Loss: 0.379993, Acc: 0.866059\n",
      "Finish 35 epochs, Loss: 0.378714, Acc: 0.866500\n",
      "Test Loss: 0.463339, Acc: 0.833267\n",
      "[36/50] Loss: 0.393811, Acc: 0.865313\n",
      "[36/50] Loss: 0.382792, Acc: 0.864792\n",
      "[36/50] Loss: 0.379499, Acc: 0.866840\n",
      "[36/50] Loss: 0.377814, Acc: 0.867188\n",
      "[36/50] Loss: 0.379331, Acc: 0.866979\n",
      "[36/50] Loss: 0.379575, Acc: 0.866806\n",
      "Finish 36 epochs, Loss: 0.379150, Acc: 0.867083\n",
      "Test Loss: 0.441345, Acc: 0.843251\n",
      "[37/50] Loss: 0.382942, Acc: 0.866250\n",
      "[37/50] Loss: 0.376811, Acc: 0.867865\n",
      "[37/50] Loss: 0.374803, Acc: 0.868681\n",
      "[37/50] Loss: 0.378767, Acc: 0.866667\n",
      "[37/50] Loss: 0.376888, Acc: 0.867375\n",
      "[37/50] Loss: 0.376655, Acc: 0.867431\n",
      "Finish 37 epochs, Loss: 0.377734, Acc: 0.866900\n",
      "Test Loss: 0.443575, Acc: 0.844050\n",
      "[38/50] Loss: 0.375546, Acc: 0.870208\n",
      "[38/50] Loss: 0.365727, Acc: 0.871771\n",
      "[38/50] Loss: 0.370850, Acc: 0.868160\n",
      "[38/50] Loss: 0.375896, Acc: 0.868021\n",
      "[38/50] Loss: 0.376797, Acc: 0.868125\n",
      "[38/50] Loss: 0.377391, Acc: 0.867917\n",
      "Finish 38 epochs, Loss: 0.377597, Acc: 0.868017\n",
      "Test Loss: 0.442722, Acc: 0.843051\n",
      "[39/50] Loss: 0.359852, Acc: 0.872813\n",
      "[39/50] Loss: 0.375457, Acc: 0.866406\n",
      "[39/50] Loss: 0.374618, Acc: 0.868090\n",
      "[39/50] Loss: 0.374893, Acc: 0.867656\n",
      "[39/50] Loss: 0.375050, Acc: 0.867292\n",
      "[39/50] Loss: 0.377026, Acc: 0.867483\n",
      "Finish 39 epochs, Loss: 0.377847, Acc: 0.867000\n",
      "Test Loss: 0.450808, Acc: 0.840755\n",
      "[40/50] Loss: 0.382130, Acc: 0.866458\n",
      "[40/50] Loss: 0.379694, Acc: 0.867760\n",
      "[40/50] Loss: 0.378390, Acc: 0.868125\n",
      "[40/50] Loss: 0.378644, Acc: 0.868125\n",
      "[40/50] Loss: 0.377862, Acc: 0.868208\n",
      "[40/50] Loss: 0.375953, Acc: 0.869219\n",
      "Finish 40 epochs, Loss: 0.375957, Acc: 0.869167\n",
      "Test Loss: 0.442404, Acc: 0.842851\n",
      "[41/50] Loss: 0.382513, Acc: 0.865938\n",
      "[41/50] Loss: 0.379323, Acc: 0.866979\n",
      "[41/50] Loss: 0.380004, Acc: 0.867361\n",
      "[41/50] Loss: 0.376674, Acc: 0.867500\n",
      "[41/50] Loss: 0.375371, Acc: 0.867125\n",
      "[41/50] Loss: 0.378293, Acc: 0.866736\n",
      "Finish 41 epochs, Loss: 0.377133, Acc: 0.867050\n",
      "Test Loss: 0.438381, Acc: 0.844848\n",
      "[42/50] Loss: 0.362226, Acc: 0.874375\n",
      "[42/50] Loss: 0.375759, Acc: 0.867917\n",
      "[42/50] Loss: 0.380975, Acc: 0.865590\n",
      "[42/50] Loss: 0.373561, Acc: 0.868229\n",
      "[42/50] Loss: 0.376218, Acc: 0.867104\n",
      "[42/50] Loss: 0.376170, Acc: 0.866788\n",
      "Finish 42 epochs, Loss: 0.376077, Acc: 0.867017\n",
      "Test Loss: 0.464265, Acc: 0.838159\n",
      "[43/50] Loss: 0.381026, Acc: 0.863125\n",
      "[43/50] Loss: 0.374945, Acc: 0.867344\n",
      "[43/50] Loss: 0.374686, Acc: 0.867535\n",
      "[43/50] Loss: 0.376111, Acc: 0.866979\n",
      "[43/50] Loss: 0.375334, Acc: 0.868437\n",
      "[43/50] Loss: 0.375710, Acc: 0.868038\n",
      "Finish 43 epochs, Loss: 0.375691, Acc: 0.867733\n",
      "Test Loss: 0.447770, Acc: 0.840355\n",
      "[44/50] Loss: 0.362563, Acc: 0.874583\n",
      "[44/50] Loss: 0.366478, Acc: 0.871042\n",
      "[44/50] Loss: 0.368442, Acc: 0.870035\n",
      "[44/50] Loss: 0.374797, Acc: 0.868932\n",
      "[44/50] Loss: 0.373008, Acc: 0.868833\n",
      "[44/50] Loss: 0.373593, Acc: 0.868507\n",
      "Finish 44 epochs, Loss: 0.374652, Acc: 0.868550\n",
      "Test Loss: 0.444963, Acc: 0.843251\n",
      "[45/50] Loss: 0.370178, Acc: 0.867083\n",
      "[45/50] Loss: 0.375018, Acc: 0.865677\n",
      "[45/50] Loss: 0.374584, Acc: 0.866736\n",
      "[45/50] Loss: 0.373546, Acc: 0.867214\n",
      "[45/50] Loss: 0.374081, Acc: 0.867229\n",
      "[45/50] Loss: 0.374182, Acc: 0.867708\n",
      "Finish 45 epochs, Loss: 0.374258, Acc: 0.867933\n",
      "Test Loss: 0.442148, Acc: 0.842053\n",
      "[46/50] Loss: 0.365021, Acc: 0.873750\n",
      "[46/50] Loss: 0.369907, Acc: 0.871042\n",
      "[46/50] Loss: 0.372173, Acc: 0.868889\n",
      "[46/50] Loss: 0.369161, Acc: 0.870339\n",
      "[46/50] Loss: 0.373171, Acc: 0.869854\n",
      "[46/50] Loss: 0.373568, Acc: 0.869167\n",
      "Finish 46 epochs, Loss: 0.373778, Acc: 0.868817\n",
      "Test Loss: 0.451071, Acc: 0.841154\n",
      "[47/50] Loss: 0.370834, Acc: 0.869583\n",
      "[47/50] Loss: 0.364383, Acc: 0.870521\n",
      "[47/50] Loss: 0.369773, Acc: 0.868889\n",
      "[47/50] Loss: 0.370773, Acc: 0.868516\n",
      "[47/50] Loss: 0.371034, Acc: 0.868646\n",
      "[47/50] Loss: 0.371800, Acc: 0.868420\n",
      "Finish 47 epochs, Loss: 0.373606, Acc: 0.867900\n",
      "Test Loss: 0.449535, Acc: 0.838359\n",
      "[48/50] Loss: 0.364990, Acc: 0.869583\n",
      "[48/50] Loss: 0.367864, Acc: 0.867031\n",
      "[48/50] Loss: 0.368568, Acc: 0.868056\n",
      "[48/50] Loss: 0.368837, Acc: 0.868490\n",
      "[48/50] Loss: 0.372514, Acc: 0.867333\n",
      "[48/50] Loss: 0.373833, Acc: 0.867656\n",
      "Finish 48 epochs, Loss: 0.373284, Acc: 0.867850\n",
      "Test Loss: 0.453959, Acc: 0.838758\n",
      "[49/50] Loss: 0.371430, Acc: 0.870521\n",
      "[49/50] Loss: 0.370143, Acc: 0.871458\n",
      "[49/50] Loss: 0.370076, Acc: 0.870799\n",
      "[49/50] Loss: 0.370891, Acc: 0.870156\n",
      "[49/50] Loss: 0.369962, Acc: 0.870229\n",
      "[49/50] Loss: 0.373828, Acc: 0.869167\n",
      "Finish 49 epochs, Loss: 0.373120, Acc: 0.869050\n",
      "Test Loss: 0.449915, Acc: 0.842053\n",
      "[50/50] Loss: 0.375103, Acc: 0.869063\n",
      "[50/50] Loss: 0.376066, Acc: 0.868594\n",
      "[50/50] Loss: 0.370941, Acc: 0.869271\n",
      "[50/50] Loss: 0.373115, Acc: 0.868099\n",
      "[50/50] Loss: 0.372138, Acc: 0.868896\n",
      "[50/50] Loss: 0.372754, Acc: 0.868889\n",
      "Finish 50 epochs, Loss: 0.372414, Acc: 0.869183\n",
      "Test Loss: 0.444712, Acc: 0.843051\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # train model\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss\n",
    "        _, predict = torch.max(out, 1)\n",
    "        running_acc += (predict == label).float().mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%300 == 0:\n",
    "            print(f'[{epoch+1}/{num_epochs}] Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}')\n",
    "    print(f'Finish {epoch+1} epochs, Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}')\n",
    "       \n",
    "    # test model\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        with torch.no_grad():\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "        eval_loss += loss\n",
    "        _, predict = torch.max(out, 1)\n",
    "        eval_acc += (predict == label).float().mean()\n",
    "\n",
    "    print(f'Test Loss: {eval_loss/len(test_loader):.6f}, Acc: {eval_acc/len(test_loader):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
